{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c172336-099a-4936-9ef0-ecc184333289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依照https://blog.csdn.net/chenzhoujian_/article/details/106873451实现\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "import mindspore.dataset as ds\n",
    "from mindspore import ops, Tensor, context\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\n",
    "from mindspore.train import Model\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from SegNet import create_dataset, SegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e600bd-a980-4773-b813-9204342e424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "def make_train_txt(num):\n",
    "    global i\n",
    "    paths = glob.glob(r\"/root/autodl-tmp/leftImg8bit/train/*/*\")\n",
    "    txt = open(\"./dataset-list/train.txt\", \"w\")\n",
    "\n",
    "    for path in paths:\n",
    "        data = path + \" \" + path.replace(\"leftImg8bit\", \"gtFine\").replace(\"gtFine.png\", \"gtFine_labelTrainIds.png\") + \"\\n\"\n",
    "        txt.write(data)\n",
    "        i = i + 1\n",
    "        if i == num:\n",
    "            break\n",
    "    i = 0\n",
    "    txt.close()\n",
    "\n",
    "def make_test_txt(num):\n",
    "    global i\n",
    "    paths = glob.glob(r\"/root/autodl-tmp/leftImg8bit/test/*/*\")\n",
    "    txt = open(\"./dataset-list/test.txt\", \"w\")\n",
    "\n",
    "    for path in paths:\n",
    "        data = path + \" \" + path.replace(\"leftImg8bit\", \"gtFine\").replace(\"gtFine.png\", \"gtFine_labelTrainIds.png\") + \"\\n\"\n",
    "        txt.write(data)\n",
    "        i = i + 1\n",
    "        if i == num:\n",
    "            break\n",
    "    i = 0\n",
    "    txt.close()\n",
    "\n",
    "def make_val_txt(num):\n",
    "    global i\n",
    "    paths = glob.glob(r\"/root/autodl-tmp/leftImg8bit/val/*/*\")\n",
    "    txt = open(\"./dataset-list/val.txt\", \"w\")\n",
    "\n",
    "    for path in paths:\n",
    "        data = path + \" \" + path.replace(\"leftImg8bit\", \"gtFine\").replace(\"gtFine.png\", \"gtFine_labelTrainIds.png\") + \"\\n\"\n",
    "        txt.write(data)\n",
    "        i = i + 1\n",
    "        if i == num:\n",
    "            break\n",
    "    i = 0\n",
    "    txt.close()\n",
    "\n",
    "train_num = 2972\n",
    "test_num = 500\n",
    "val_num = 1525\n",
    "\n",
    "make_train_txt(train_num)\n",
    "make_test_txt(test_num)\n",
    "make_val_txt(val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af261f-99dc-4b46-823d-b210b1ea51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动设置超参数\n",
    "CLASS_NUM = 19\n",
    "CATE_WEIGHT = [1.0] * CLASS_NUM\n",
    "EPOCH = 20\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "# 为什么要用这个矩阵https://blog.csdn.net/fanzonghao/article/details/85263553\n",
    "# 该矩阵生成文件为couter.py\n",
    "CATE_WEIGHT = [\n",
    "    0.11921289124514069, 0.9772031489113517, 0.2606578051907899,\n",
    "    9.068186030082103, 6.772279222279968, 4.845227365263553,\n",
    "    28.52810833819015, 10.758335113118157, 0.3736856892826064,\n",
    "    5.133604194351756, 1.4827554927399786, 4.886283011781665,\n",
    "    44.10664265269921, 0.8495922090922964, 22.22468639649049,\n",
    "    25.267384685741828, 25.526398354063044, 60.29661028702076,\n",
    "    14.370822828405153\n",
    "]\n",
    "TXT_PATH = \"./dataset-list/train.txt\"\n",
    "PRE_TRAINING = \"vgg16_bn-6c64b313.pth\"\n",
    "WEIGHTS = \"./weights/\"\n",
    "\n",
    "# 确保权重保存路径存在\n",
    "if not os.path.exists(WEIGHTS):\n",
    "    os.makedirs(WEIGHTS)\n",
    "\n",
    "# 加载数据\n",
    "train_data = create_dataset(txt_path=TXT_PATH, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3defa-2f10-4d2c-8d76-0355d08794be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(SegNet, train_data):\n",
    "\n",
    "    # 加载预训练权重\n",
    "    SegNet.load_weights(PRE_TRAINING)\n",
    "\n",
    "    # 构造数据集\n",
    "    train_dataset = ds.GeneratorDataset(\n",
    "        source=train_data, column_names=[\"image\", \"label\"], shuffle=True\n",
    "    )\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    # 定义优化器\n",
    "    optimizer = nn.SGD(SegNet.trainable_params(), learning_rate=LR, momentum=MOMENTUM)\n",
    "\n",
    "    # 定义损失函数\n",
    "    weight = Tensor(np.array(CATE_WEIGHT).astype(np.float32))\n",
    "    loss_func = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "\n",
    "    # 设置模型\n",
    "    model = Model(SegNet, loss_func=loss_func, optimizer=optimizer)\n",
    "\n",
    "    # 定义 Loss 监控器\n",
    "    loss_monitor = LossMonitor()\n",
    "\n",
    "    # 保存训练 Loss\n",
    "    losses = []\n",
    "\n",
    "    print(\"Start Training...\")\n",
    "    for epoch in range(EPOCH):\n",
    "        for step, data in enumerate(train_dataset.create_dict_iterator()):\n",
    "            b_x = data[\"image\"]\n",
    "            b_y = data[\"label\"]\n",
    "            b_y = ops.Reshape()(b_y, (BATCH_SIZE, 224, 224))  # 确保标签形状正确\n",
    "\n",
    "            # 前向计算和梯度更新\n",
    "            output = SegNet(b_x)\n",
    "            loss = loss_func(output, b_y)\n",
    "            losses.append(loss.asnumpy().item())\n",
    "\n",
    "            optimizer.clear_grad()  # 梯度清零\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 更新参数\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(f\"Epoch: {epoch} || Step: {step} || Loss: {loss.asnumpy():.4f}\")\n",
    "\n",
    "    # 保存模型权重\n",
    "    save_path = WEIGHTS + \"SegNet_weights.ckpt\"\n",
    "    ms.save_checkpoint(SegNet, save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "    # 绘制 Loss 曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(losses, label=\"Training Loss\")\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"Loss.svg\")\n",
    "    plt.show()\n",
    "\n",
    "    return losses\n",
    "\n",
    "# 初始化模型并开始训练\n",
    "SegNet = SegNet(3, CLASS_NUM)\n",
    "losses = train(SegNet, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ae288-eac7-4fc4-8e33-73745a61d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 颜色映射表\n",
    "COLORS = [\n",
    "    [128, 64, 128],  # 'road'\n",
    "    [244, 35, 232],  # 'sidewalk'\n",
    "    [70, 70, 70],    # 'building'\n",
    "    [102, 102, 156], # 'wall'\n",
    "    [190, 153, 153], # 'fence'\n",
    "    [153, 153, 153], # 'pole'\n",
    "    [250, 170, 30],  # 'traffic light'\n",
    "    [220, 220, 0],   # 'traffic sign'\n",
    "    [107, 142, 35],  # 'vegetation'\n",
    "    [152, 251, 152], # 'terrain'\n",
    "    [70, 130, 180],  # 'sky'\n",
    "    [220, 20, 60],   # 'person'\n",
    "    [255, 0, 0],     # 'rider'\n",
    "    [0, 0, 142],     # 'car'\n",
    "    [0, 0, 70],      # 'truck'\n",
    "    [0, 60, 100],    # 'bus'\n",
    "    [0, 80, 100],    # 'train'\n",
    "    [0, 0, 230],     # 'motorcycle'\n",
    "    [119, 11, 32]    # 'bicycle'\n",
    "]\n",
    "\n",
    "MODE = 1\n",
    "SAMPLES = \"samples/\"\n",
    "OUTPUTS = \"outputs/\"\n",
    "WEIGHTS = \"weights/SegNet_weights.pth\"\n",
    "\n",
    "alpha = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2388b-f40f-4068-a382-65db8e473da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(SegNet):\n",
    "    if MODE:\n",
    "        # 加载预训练权重\n",
    "        ms.load_checkpoint(WEIGHTS, net=SegNet)\n",
    "    SegNet.set_train(False)\n",
    "\n",
    "    # 获取所有测试图片\n",
    "    paths = os.listdir(SAMPLES)\n",
    "\n",
    "    for path in paths:\n",
    "        # 加载并预处理图像\n",
    "        image_src = Image.open(os.path.join(SAMPLES, path)).convert(\"RGB\")  # 加载图像并转换为RGB模式\n",
    "        image_src_resized = image_src.resize((224, 224))  # 调整大小到网络输入\n",
    "        image = np.array(image_src_resized) / 255.0  # 归一化到 [0, 1]\n",
    "        image = np.transpose(image, (2, 0, 1))  # 转换为 (C, H, W)\n",
    "        image = Tensor(image[np.newaxis, ...], dtype=mindspore.float32)  # 添加批次维度\n",
    "\n",
    "        # 模型推理\n",
    "        output = SegNet(image)\n",
    "        output = ops.ResizeBilinear((1024, 2048), align_corners=False)(output)  # 调整到目标尺寸\n",
    "        output = ops.Argmax(axis=1)(output).asnumpy().squeeze()  # 获取预测类别并移除批次维度\n",
    "\n",
    "        # 生成分割图像\n",
    "        image_seg = np.zeros((1024, 2048, 3), dtype=np.uint8)\n",
    "        for c in range(CLASS_NUM):\n",
    "            mask = (output == c)\n",
    "            image_seg[mask] = COLORS[c]\n",
    "\n",
    "        # 将分割结果与原图结合（透明度混合）\n",
    "        image_src_resized_back = image_src.resize((2048, 1024))  # 将原图调整到分割结果大小\n",
    "        image_src_array = np.array(image_src_resized_back)  # 转换为数组\n",
    "        alpha = 0.5  # 设置透明度\n",
    "        image_blend = (image_src_array * (1 - alpha) + image_seg * alpha).astype(np.uint8)  # 混合\n",
    "\n",
    "        # 保存结果\n",
    "        os.makedirs(OUTPUTS, exist_ok=True)\n",
    "        result = Image.fromarray(image_blend)\n",
    "        result.show()  # 显示图片\n",
    "        result.save(os.path.join(OUTPUTS, path))\n",
    "        # print(f\"{path} is done!\")\n",
    "\n",
    "# 调用测试函数\n",
    "test(SegNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd2366-0350-4ab1-8242-70e830244d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PATHS = \"./dataset-list/val.txt\"\n",
    "\n",
    "def calculate_mIoU(val_paths, model, class_num):\n",
    "    mIoU = []\n",
    "    with open(val_paths, \"r\") as paths:\n",
    "        for index, line in enumerate(paths):\n",
    "            line = line.strip()\n",
    "            path = line.split()\n",
    "\n",
    "            # 加载图像\n",
    "            image = cv.imread(path[0])\n",
    "            image = cv.resize(image, (224, 224))\n",
    "            image = image / 255.0  # 归一化输入\n",
    "            image = np.transpose(image, (2, 0, 1))  # 转换为 (C, H, W)\n",
    "            image = Tensor(image[np.newaxis, ...], dtype=mindspore.float32)  # 添加批次维度\n",
    "\n",
    "            # 模型推理\n",
    "            model.set_train(False)\n",
    "            output = model(image)\n",
    "            output = ops.Argmax(axis=1)(output).asnumpy().squeeze()  # 获取类别预测结果\n",
    "            predict = cv.resize(np.uint8(output), (2048, 1024))  # 调整大小\n",
    "\n",
    "            # 加载标签\n",
    "            label = cv.imread(path[1], cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # 计算 IoU\n",
    "            intersection, union = [], []\n",
    "            for i in range(1, class_num):\n",
    "                intersect = np.sum((predict == i) & (label == i))\n",
    "                union_area = np.sum(predict == i) + np.sum(label == i) - intersect\n",
    "                intersection.append(intersect)\n",
    "                union.append(union_area)\n",
    "\n",
    "            iou = [inter / u if u > 0 else 0 for inter, u in zip(intersection, union)]\n",
    "            mIoU.append(np.mean(iou))\n",
    "\n",
    "            print(f\"miou_{index}: {mIoU[index]:.4f}\")\n",
    "    return mIoU\n",
    "\n",
    "mIoU = calculate_mIoU(VAL_PATHS, SegNet, CLASS_NUM)\n",
    "\n",
    "result_file = \"result.txt\"\n",
    "mean_mIoU = np.mean(mIoU)\n",
    "print(\"\\n\")\n",
    "print(f\"mIoU: {mean_mIoU:.4f}\")\n",
    "\n",
    "with open(result_file, \"a\") as file:\n",
    "    file.write(f\"评价日期：{time.asctime(time.localtime(time.time()))}\\n\")\n",
    "    file.write(f\"使用的权重：{WEIGHTS}\\n\")\n",
    "    file.write(f\"mIoU: {mean_mIoU:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
